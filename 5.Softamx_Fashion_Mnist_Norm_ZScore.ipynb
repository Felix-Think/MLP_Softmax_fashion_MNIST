{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "VuTAK7n6Hd"
      },
      "source": [
        "import torchvision\n",
        "import torch\n",
        "from torchvision.datasets import FashionMNIST\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "Zn3XTTyha6"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "gb6F4ekskV"
      },
      "source": [
        "# Load data\n",
        "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "\n",
        "\n",
        "dataset = torchvision.datasets.FashionMNIST(root='data',\n",
        "                                            train=True,\n",
        "                                            transform=transform,\n",
        "                                            download=True)\n",
        "loader = torch.utils.data.DataLoader(dataset,\n",
        "                                     batch_size = 1024,\n",
        "                                     shuffle = False,\n",
        "                                     num_workers = 4)\n",
        "\n",
        "mean = 0.0\n",
        "for images, _ in loader:\n",
        "    batch_samples = images.size(0)  # Batch size\n",
        "    images = images.view(batch_samples, images.size(1), -1) # convert from (batch, 1, 28, 28) to (batch, 1, 784)\n",
        "    mean += images.mean(2).sum(0)\n",
        "mean = mean / len(loader.dataset)\n",
        "\n",
        "variance = 0.0\n",
        "for images, _ in loader:\n",
        "    batch_samples = images.size(0)\n",
        "    images = images.view(batch_samples, images.size(1), -1) # convert from (batch, 1, 28, 28) to (batch, 1, 784)\n",
        "    variance += ((images - mean.unsqueeze(1))**2).sum([0,2]) # unsqueeze used to create a new dimension to\n",
        "    # match the dimension of images\n",
        "    std = torch.sqrt(variance / (len(loader.dataset)*28*28)) # 28*28 is the size of the image, len of the dataset is the number of images\n",
        "\n",
        "print(mean, std)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "ymrCA5Sgoh"
      },
      "source": [
        "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
        "                                            transforms.Normalize((mean, ), (std, ))])\n",
        "train_data = FashionMNIST(root = 'data',\n",
        "                          train = True,\n",
        "                          download = True,\n",
        "                          transform = transform)\n",
        "data_loader = DataLoader(dataset = train_data, batch_size = 1024, shuffle = True)\n",
        "\n",
        "test_data = FashionMNIST(root = 'data',\n",
        "                         train = False,\n",
        "                         download = True,\n",
        "                         transform = transform)\n",
        "test_loader = DataLoader(dataset = test_data, batch_size = 1024, shuffle = True)\n",
        "\n",
        "\n",
        "# Print 1 image\n",
        "image, label = train_data[0]\n",
        "print(image.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "E5ZnnUa2fH"
      },
      "source": [
        "#Define show image function\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def show_image(image):\n",
        "    image = image / 2.0 + 0.5\n",
        "    img = image.numpy()\n",
        "    img = np.transpose(img, (1, 2, 0))\n",
        "    plt.imshow(img, cmap = 'gray')\n",
        "    plt.show()\n",
        "\n",
        "for i, (images, label) in enumerate(data_loader):\n",
        "    show_image(torchvision.utils.make_grid(images[:8]))\n",
        "    break"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "YTco5aW1i9"
      },
      "source": [
        "# Define model\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(784, 10)\n",
        ")\n",
        "\n",
        "model.to(device)\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "0AkB01GvaC"
      },
      "source": [
        "input_tensor = torch.randn(5, 28, 28).to(device)\n",
        "output = model(input_tensor)\n",
        "print(output.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "Wk1VQ6pvWN"
      },
      "source": [
        "# Define Loss, Optimizer, and evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "yHJkbC7OLH"
      },
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    test_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    test_loss = test_loss / len(test_loader)\n",
        "    return test_loss , accuracy"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "kjnpUU0n5u"
      },
      "source": [
        "test_loss ,accuracy = evaluate(model, test_loader, criterion)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "xMsFpvWbAy"
      },
      "source": [
        "#Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "lgehGX8kEb"
      },
      "source": [
        "#define paremeters\n",
        "train_loss = []\n",
        "train_accuracy = []\n",
        "test_loss = []\n",
        "test_accuracy = []\n",
        "\n",
        "# Train the model\n",
        "max_epochs = 100\n",
        "for epoch in range(max_epochs):\n",
        "    # Initialize some parameters\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0.0\n",
        "    total = 0\n",
        "    \n",
        "    for i, (images, labels) in enumerate(data_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        #Determine class predictions and accuracy\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        running_corrects += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        # Backward and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_accuracy = 100 * running_corrects / total\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    test_loss_epoch, test_accuracy_epoch = evaluate(model, test_loader, criterion)\n",
        "    print(f\"Epoch {epoch+1}/{max_epochs}, Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.2f}%, Test Loss: {test_loss_epoch:.4f}, Test Accuracy: {test_accuracy_epoch:.2f}%\")\n",
        "    train_loss.append(epoch_loss)\n",
        "    train_accuracy.append(epoch_accuracy)\n",
        "    test_loss.append(test_loss_epoch)\n",
        "    test_accuracy.append(test_accuracy_epoch)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "THp4pAElPV"
      },
      "source": [
        "# Plot loss and accuracy\n",
        "plt.plot(train_loss, label = 'train loss')\n",
        "plt.plot(test_loss, label = 'test loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "26veYTqK8L"
      },
      "source": [
        "plt.plot(train_accuracy, label = 'train accuracy')\n",
        "plt.plot(test_accuracy, label = 'test accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}