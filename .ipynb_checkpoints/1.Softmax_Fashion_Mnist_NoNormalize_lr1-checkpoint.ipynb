{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "4G0NMdK8Vd"
      },
      "source": [
        "from torchvision.datasets import FashionMNIST\n",
        "import torchvision\n",
        "import torch\n",
        "from torchvision.transforms import transforms\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "9z3lQSXPTg"
      },
      "source": [
        "#Check if GPU is availale\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "nlGxDdQdY5"
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0,), (1.0/255.0,))]) # mean = 0, std = 1/255\n",
        "# Load the FashionMNIST dataset\n",
        "train_set = FashionMNIST(root = 'data',\n",
        "                         train = True,\n",
        "                         download = True,\n",
        "                         transform = transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=1024, num_workers=4, shuffle=True)\n",
        "test_set = FashionMNIST(root = 'data',\n",
        "                        train = False,\n",
        "                        download = True,\n",
        "                        transform = transform)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1024, num_workers=4, shuffle=False)\n",
        "\n",
        "#Print a sample of the data\n",
        "img, _ = train_set[0]\n",
        "print(img.size())\n",
        "print(type(img))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "ekyofPJUeU"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "qeI7T7XRdm"
      },
      "source": [
        "#Function to display images\n",
        "def show_images(image):\n",
        "    fig = plt.figure(figsize = (9, 9))\n",
        "    img = image.numpy()\n",
        "    img = np.transpose(img, (1, 2, 0))\n",
        "    plt.imshow(img)\n",
        "\n",
        "for i, (images, labels) in enumerate(data_loader, 0):\n",
        "    plt.axis('off')\n",
        "    show_images(torchvision.utils.make_grid(images[:8])) # Show the first 8 images in each batch, so we can break the loop\n",
        "    break"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "euKVpfP4rr"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "9DkleJcujH"
      },
      "source": [
        "# Define the model\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(784, 10)\n",
        ")\n",
        "model = model.to(device)\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "NBi1LUEQR9"
      },
      "source": [
        "# Initialize the random weights of the model\n",
        "\n",
        "input_tensor = torch.rand(5, 28, 28).to(device) # Create a random tensor of size 5 x 28 x 28, 5 images of 28 x 28 pixels\n",
        "output = model(input_tensor)\n",
        "\n",
        "print(f\"Input tensor shape: {output.shape}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "Y9qyo73IQm"
      },
      "source": [
        "# LOSS, OPTIMIZER, EVALUATION FUNCTIOn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "lDuGz1y3rg"
      },
      "source": [
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01) # SGD is stand for Stochastic Gradient Descent"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "nSML0OSFhL"
      },
      "source": [
        "def evaluation(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # in this case we don't need to calculate the gradients so we use torch.no_grad()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            #move the images and labels to the device the model is on\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item() # item() is used to convert the tensor value to a python number\n",
        "            \n",
        "            _, predicted = torch.max(outputs.data, 1) # Get the predicted class with the highest probalility\n",
        "            #print(f'Shape of predicted: {predicted.shape}')\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    test_loss = test_loss / len(test_loader) # Average loss\n",
        "\n",
        "    return test_loss, accuracy\n",
        "    "
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "kN8eatoQBh"
      },
      "source": [
        "test_loss, accuracy = evaluation(model, test_loader, criterion)\n",
        "print(f'Test loss: {test_loss}')\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "mHOdIau8B1"
      },
      "source": [
        "#train\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "epochs = 100\n",
        "\n",
        "for  epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    running_correct = 0   # to track number of correct predictions\n",
        "    total = 0             # to track total number of samples    \n",
        "    for i, (images, labels) in enumerate(train_loader, 0):\n",
        "        #move input and labels to the device\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Forward\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Determine the predicted classes\n",
        "        _, predicted = torch.max(outputs, 1) # Get the predicted values with every sample\n",
        "        total += labels.size(0)\n",
        "        running_correct += (predicted == labels).sum().item()\n",
        "        # Backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    epoch_accuracy = 100 * running_correct / total\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    test_loss, test_accuracy = evaluation(model, test_loader, criterion)\n",
        "    print(f'Epoch: {epoch + 1} / {epochs}: Train Loss: {epoch_loss:.4f} Train Accuracy: {epoch_accuracy:.4f} Test Loss: {test_loss:4f} Test Accuracy: {test_accuracy:4f}')\n",
        "\n",
        "    train_losses.append(epoch_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    train_accuracies.append(epoch_accuracy)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "        "
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "2eYBAljiga"
      },
      "source": [
        "#Plot train and test losses\n",
        "\n",
        "plt.plot(train_losses, label = 'train loss')\n",
        "plt.plot(test_losses, label = 'test loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "W9Pwu811qY"
      },
      "source": [
        "#Plot train and test accuracies\n",
        "plt.plot(train_accuracies, label = 'train accuracy')\n",
        "plt.plot(test_accuracies, label = 'test accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}